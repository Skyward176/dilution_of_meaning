{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dilution of Meaning: Multi-Text Experiment\n",
                "\n",
                "This notebook scales the iterative rewriting experiment to process all text files in the `texts/` directory. It also introduces semantic tracking using embeddings and PCA (Principal Component Analysis) to visualize how the meaning of each text \"drifts\" across iterations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Environment Setup\n",
                "\n",
                "First, we install and import the necessary libraries. This includes `transformers` for the LLM, `sentence-transformers` for embeddings, and `scikit-learn` for PCA."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q sentence-transformers scikit-learn matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cpu\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import glob\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from transformers import pipeline\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.decomposition import PCA\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Set device\n",
                "device = \"cpu\"\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    device = toch.device(\"cuda\")\n",
                "\n",
                "print(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Initialization\n",
                "\n",
                "We initialize two models:\n",
                "1.  **Generation Model**: The larger LLM used for rewriting (`google/gemma-3n-E2B-it`).\n",
                "2.  **Embedding Model**: A specialized model for generating semantic vectors (`all-MiniLM-L6-v2`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Large Language Model for Generation\n",
                "gen_model_id = \"google/gemma-3n-E2B-it\" \n",
                "# Note: \"ServiceNow-AI/Apriel-1.5-15b-Thinker\" can be used if hardware supports it.\n",
                "\n",
                "print(f\"Loading Generation Model: {gen_model_id}...\")\n",
                "pipe = pipeline(\"text-generation\", model=gen_model_id, device=device)\n",
                "\n",
                "# Sentence Transformer for Embeddings\n",
                "print(\"Loading Embedding Model...\")\n",
                "embed_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Multi-Text Execution Loop\n",
                "\n",
                "We discover all `.txt` files in the `texts/` directory and run the rewriting experiment on each. We store the text and its embedding at every step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text_files = glob.glob(\"./texts/*.txt\")\n",
                "iterations = 4\n",
                "results = {} # {filename: {'texts': [...], 'embeddings': [...]}}\n",
                "\n",
                "# Clear or create output.txt\n",
                "with open(\"output_txt_all.txt\", \"w\") as f:\n",
                "    f.write(\"Dilution of Meaning: All Texts Experiment\\n\\n\")\n",
                "\n",
                "for file_path in tqdm(text_files, desc=\"Processing Files\"):\n",
                "    file_name = os.path.basename(file_path)\n",
                "    print(f\"\\nProcessing: {file_name}\")\n",
                "    \n",
                "    with open(file_path, \"r\") as f:\n",
                "        current_text = f.read().strip()\n",
                "    \n",
                "    file_results = {'texts': [current_text], 'embeddings': []}\n",
                "    \n",
                "    # Generate embedding for original text\n",
                "    orig_embedding = embed_model.encode(current_text)\n",
                "    file_results['embeddings'].append(orig_embedding)\n",
                "    \n",
                "    with open(\"output_txt_all.txt\", \"a\") as output_file:\n",
                "        output_file.write(f\"--- FILE: {file_name} ---\\n\")\n",
                "        output_file.write(f\"Original:\\n{current_text}\\n\\n\")\n",
                "    \n",
                "    for i in range(1, iterations + 1):\n",
                "        summarize_prompt = [\n",
                "            {'role': 'system', 'content': 'Rewrite this passage in your own words and in a similar length and style.'},\n",
                "            {'role': 'user', 'content': current_text}\n",
                "        ]\n",
                "        \n",
                "        # Generate rewrite\n",
                "        output = pipe(\n",
                "            summarize_prompt,\n",
                "            max_new_tokens=2000,\n",
                "            return_full_text=False,\n",
                "            do_sample=True,\n",
                "            temperature=0.7,\n",
                "            tokenizer_encode_kwargs={\"enable_thinking\": False},\n",
                "        )\n",
                "        \n",
                "        generated_text = output[0][\"generated_text\"]\n",
                "        \n",
                "        # Generate embedding for the rewrite\n",
                "        new_embedding = embed_model.encode(generated_text)\n",
                "        \n",
                "        file_results['texts'].append(generated_text)\n",
                "        file_results['embeddings'].append(new_embedding)\n",
                "        \n",
                "        with open(\"output_txt_all.txt\", \"a\") as output_file:\n",
                "            output_file.write(f\"Iteration {i}:\\n{generated_text}\\n\\n\")\n",
                "        \n",
                "        current_text = generated_text\n",
                "    \n",
                "    results[file_name] = file_results\n",
                "\n",
                "print(\"\\nAll processing complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization: Semantic Drift\n",
                "\n",
                "We use PCA to reduce the embeddings to 2D and plot the trajectories of each file. This shows how the \"meaning\" of the text moves in semantic space as it is rewritten."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Flatten all embeddings to fit PCA\n",
                "all_embeddings = []\n",
                "labels = []\n",
                "for file_name, data in results.items():\n",
                "    all_embeddings.extend(data['embeddings'])\n",
                "    for i in range(len(data['embeddings'])):\n",
                "        labels.append((file_name, i))\n",
                "\n",
                "all_embeddings = np.array(all_embeddings)\n",
                "\n",
                "# Apply PCA\n",
                "pca = PCA(n_components=2)\n",
                "embeddings_2d = pca.fit_transform(all_embeddings)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(12, 8))\n",
                "colors = plt.cm.rainbow(np.linspace(0, 1, len(results)))\n",
                "\n",
                "for idx, (file_name, data) in enumerate(results.items()):\n",
                "    # Get start and end indices in the flattened array\n",
                "    start_idx = idx * (iterations + 1)\n",
                "    end_idx = start_idx + (iterations + 1)\n",
                "    \n",
                "    coords = embeddings_2d[start_idx:end_idx]\n",
                "    \n",
                "    # Plot the line (trajectory)\n",
                "    plt.plot(coords[:, 0], coords[:, 1], color=colors[idx], alpha=0.5, linestyle='--')\n",
                "    \n",
                "    # Plot the points (Original and Iterations)\n",
                "    for i, (x, y) in enumerate(coords):\n",
                "        marker = 'o' if i == 0 else 'x'\n",
                "        marker_size = 100 if i == 0 else 50\n",
                "        plt.scatter(x, y, color=colors[idx], marker=marker, s=marker_size, label=f\"{file_name} (orig)\" if i == 0 else \"\")\n",
                "        plt.text(x, y, f\"{i}\", fontsize=9)\n",
                "        \n",
                "plt.title(\"Dilution of Meaning: Semantic Drift across Iterations (PCA 2D)\")\n",
                "plt.xlabel(\"PCA Component 1\")\n",
                "plt.ylabel(\"PCA Component 2\")\n",
                "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
                "plt.grid(True, linestyle=':', alpha=0.6)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
